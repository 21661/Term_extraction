{
  "summary":"Toward a `Standard Model' of Machine Learning",
  "chunks":
  {
    "1": "Machine learning (ML) is about computational methods that enable machines to learn concepts from experience. In handling a wide variety of experience ranging from data instances, knowledge, constraints, to rewards, adversaries, and lifelong interaction in an ever-growing spectrum of tasks, contemporary ML/AI (artificial intelligence) research has resulted in a multitude of learning paradigms and methodologies. Despite the continual progresses on all different fronts, the disparate narrowly focused methods also make standardized, composable, and reusable development of ML approaches difficult, and preclude the opportunity to build AI agents that panoramically learn from all types of experience. This article presents a standardized ML formalism, in particular a ‘standard equation’ of the learning objective, that offers a unifying understanding of many important ML algorithms in the supervised, unsupervised, knowledge-constrained, reinforcement",
    "2": "where θ denotes model parameters, Θ the feasible set, E the space of experience, fθ the model mapping from experience to predictions or actions, \nℓ\nℓ the loss function over experience, and \nΩ\nΩ a regularisation or complexity penalty. By varying E, ℓℓ, ΩΩ, and feasible set ΘΘ, one recovers supervised / unsupervised, constrained / unconstrained, reinforcement, and adversarial learning as special cases. Through the composability of this formalism, we further highlight how hybrid methods, transfer learning, meta-learning, and lifelong learning can be encoded in the same equation by expanding the definition of experience and objective. The goal is to offer a language for describing ML methods in a uniform way, thereby promoting modular design, better reuse across problems, and easier evaluation of general-purpose learners."
  }
}


import asyncio
from typing import List, Dict
from langchain_core.runnables import Runnable
from langgraph.graph import StateGraph, END
import spacy, json, time, logging, re
from utils.LLMClientManager import LLMclientManager
from utils.Get_term import (
     translate_batch_async, translate_term_async,
)
from utils.workflow_adapter import _unwrap
from utils.TimeNode import timed_node

import typing
from utils.TermState import TermState
from Nodes._reflect_node import reflect_sync_node,route_after_reflect
from Nodes.select_top_terms import select_top_terms
from Nodes._terms_only_batch import _terms_only_batch

# ===================== 2ï¸âƒ£ åˆå§‹åŒ– =====================
nlp = spacy.load("en_core_web_trf")

# logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===================== 9ï¸âƒ£ æ„å»º LangGraph å·¥ä½œæµï¼ˆé‡æ„ä¸º main.extract çš„æ‰¹å¤„ç†æµç¨‹ï¼‰ =====================
_TERMS_ONLY_WORKFLOW = None


@timed_node()
def _init_extract_state(state: TermState) -> TermState:
    original: TermState | tuple | dict = state
    inner, parent, key = _unwrap(state)
    sd: TermState = typing.cast(TermState, inner if isinstance(inner, dict) else TermState())
    # ä»…åˆå§‹åŒ–ç¼ºå¤±çš„é”®ï¼Œé¿å…é‡å¤å†™å…¥
    updates: TermState = {}
    if "summary" not in sd:
        updates["summary"] = sd.get("summary", "") or ""
    return typing.cast(TermState, updates)


@timed_node()
def _aggregate_unique_terms(state: TermState) -> TermState:
    inner, parent, key = _unwrap(state)
    sd: TermState = typing.cast(TermState, inner if isinstance(inner, dict) else TermState())

    # --- ä¿®æ”¹å¼€å§‹ ---
    # ä¸è¦è¯»å– sd["selected_terms"]ï¼Œå› ä¸ºå®ƒå¯èƒ½è¢«å¹¶è¡Œè¦†ç›–äº†
    # ä»ç»“æ„åŒ–çš„ chunk_terms ä¸­æå–æ‰€æœ‰å‡ºç°è¿‡çš„æœ¯è¯­
    chunk_terms_data = sd.get("chunk_terms", [])
    all_extracted_terms = []

    if chunk_terms_data:
        for item in chunk_terms_data:
            # item æ˜¯ {'chunk_id': '...', 'terms': [...]}
            terms = item.get("terms", [])
            if isinstance(terms, list):
                all_extracted_terms.extend(terms)

    # å»é‡
    unique_terms = sorted(set(t for t in all_extracted_terms if isinstance(t, str) and t.strip()))
    # --- ä¿®æ”¹ç»“æŸ ---

    logger.info("Aggregated %d unique terms from chunks for translation.", len(unique_terms))
    return typing.cast(TermState, {"unique_terms": unique_terms})


@timed_node()
async def _single_translate_concurrent(state: TermState) -> TermState:
    """
    ç¿»è¯‘èŠ‚ç‚¹ï¼ˆæè‡´æ€§èƒ½ç‰ˆï¼‰
    """
    inner, parent, key = _unwrap(state)
    sd: TermState = typing.cast(TermState, inner if isinstance(inner, dict) else TermState())

    unique_terms: List[str] = sd.get("unique_terms", [])
    topic = sd.get("summary", "")
    translations_map: Dict[str, List[str]] = {}

    if not unique_terms:
        return typing.cast(TermState, {"translations_map": translations_map})

    # æ£€æŸ¥æ˜¯å¦æœ‰ MT æ¨¡å‹
    target_mt_model = "tencent/Hunyuan-MT-7B"
    has_mt_model = LLMclientManager.check_model_exists(target_mt_model)

    if has_mt_model:
        # =====================================================
        # ç­–ç•¥ A: å•è¯é«˜å¹¶å‘ (MT æ¨¡å‹)
        # =====================================================
        logger.info(f"ğŸš€ å¯ç”¨ MT é«˜å¹¶å‘æ¨¡å¼ ({target_mt_model})")

        # ä¿¡å·é‡ï¼šæ§åˆ¶åŒæ—¶é£åœ¨å¤©ä¸Šçš„è¯·æ±‚æ•°ï¼Œé˜²æ­¢ API é™æµ
        # å»ºè®®æ ¹æ®ä½ çš„ API é¢åº¦è°ƒæ•´ï¼Œ100 æ˜¯ä¸ªæ¿€è¿›ä½†é«˜æ•ˆçš„å€¼
        semaphore = asyncio.Semaphore(100)

        async def worker(term):
            async with semaphore:
                # å¤±è´¥è‡ªåŠ¨é‡è¯• 2 æ¬¡
                for _ in range(2):
                    res = await translate_term_async(term, topic, target_mt_model)
                    if res: return term, res
                    # ç¨å¾®é€€é¿ä¸€ä¸‹
                    # await asyncio.sleep(0.1)
                return term, []

        # åˆ›å»ºä»»åŠ¡å¹¶å‘æ‰§è¡Œ
        tasks = [worker(t) for t in unique_terms]
        results = await asyncio.gather(*tasks)

        for term, res in results:
            translations_map[term] = res

    else:
        # =====================================================
        # ç­–ç•¥ B: æ‰¹é‡åˆ†å— (é€šç”¨æ¨¡å‹)
        # =====================================================
        logger.info("ğŸ“¦ å¯ç”¨é€šç”¨æ¨¡å‹æ‰¹é‡æ¨¡å¼")

        batch_size = 20  # é€šç”¨æ¨¡å‹ä¸€æ¬¡å¤„ç† 20 ä¸ªè¯æ¯”è¾ƒç¨³
        max_concurrency = 10  # æ§åˆ¶å¹¶å‘æ•°

        semaphore = asyncio.Semaphore(max_concurrency)

        # åˆ‡åˆ†åˆ—è¡¨
        chunks = [unique_terms[i:i + batch_size] for i in range(0, len(unique_terms), batch_size)]

        async def worker_batch(chunk):
            async with semaphore:
                for _ in range(2):  # ç®€å•é‡è¯•
                    res = await translate_batch_async(chunk, topic)
                    if res: return res
                return {}

        tasks = [worker_batch(c) for c in chunks]
        results = await asyncio.gather(*tasks)

        for batch_map in results:
            if batch_map:
                translations_map.update(batch_map)

    # å…œåº•æ£€æŸ¥
    missing = 0
    for t in unique_terms:
        if t not in translations_map:
            translations_map[t] = []
            missing += 1

    logger.info(f"ç¿»è¯‘å®Œæˆã€‚æ€»æ•°: {len(translations_map)}, è¡¥å…¨ç©ºç¼º: {missing}")
    return typing.cast(TermState, {"translations_map": translations_map})


def _assemble_annotations(state: TermState) -> TermState:
    import re
    original = state
    inner, parent, key = _unwrap(state)
    sd: TermState = typing.cast(TermState, inner if isinstance(inner, dict) else TermState())

    per_chunk_results = sd.get("chunk_terms", [])
    translations_map: Dict[str, List[str]] = sd.get("translations_map", {})
    term_annotations: Dict[str, typing.Any] = {}

    def lookup_candidates(t: str):
        key_raw = t
        key_lower = t.lower().strip()
        return (
                translations_map.get(key_raw) or
                translations_map.get(key_lower) or
                []
        )

    # --- ä¿®æ”¹ç‚¹ 1ï¼š_pick_best é€»è¾‘ä¿®æ­£ ---
    def _pick_best(term: str, cands: List[str]) -> typing.Optional[str]:
        # åªæœ‰å½“å®Œå…¨æ²¡æœ‰å€™é€‰è¯æ—¶ï¼Œæ‰è§†ä¸ºâ€œå¤±è´¥â€ï¼Œè¿”å› None
        if not cands:
            return None

        filtered = [c.strip() for c in cands if c and c.strip()]
        if not filtered:
            return None

        term_norm = term.strip().lower()

        # ä¼˜å…ˆç­–ç•¥ä¸å˜ï¼šå…ˆæ‰¾ä¸­æ–‡
        for c in filtered:
            if re.search(r"[\u4e00-\u9fff]", c):
                return c

        # å…¶æ¬¡ï¼šæ‰¾å’ŒåŸæ–‡ä¸ä¸€æ ·çš„ï¼ˆæ¯”å¦‚å…¨ç§°æ‰©å±•ï¼‰
        for c in filtered:
            if c.lower() != term_norm:
                return c

        # ã€å…³é”®ä¿®æ­£ã€‘ï¼šå¦‚æœåªå‰©ä¸‹å’ŒåŸæ–‡ä¸€æ ·çš„è¯ï¼ˆä¾‹å¦‚ AVL -> AVLï¼‰ï¼Œç›´æ¥è¿”å›å®ƒ
        # åªè¦ç¿»è¯‘è¡¨é‡Œæœ‰å®ƒï¼Œå°±è¯´æ˜å®ƒæ˜¯æœ‰æ•ˆç»“æœ
        return filtered[0]

    for chunk_item in per_chunk_results:
        cid = chunk_item.get("chunk_id")
        terms = chunk_item.get("terms", [])

        items = []
        for t in terms:
            cands = lookup_candidates(t)

            # è¿™é‡Œçš„ cands å¦‚æœæ˜¯ []ï¼Œ_pick_best ä¼šè¿”å› None
            chosen = _pick_best(t, cands)

            # --- ä¿®æ”¹ç‚¹ 2ï¼šåªè¿‡æ»¤ None ---
            if chosen is None:
                # è¯´æ˜ç¿»è¯‘è¡¨é‡Œæ ¹æœ¬æ²¡è¿™ä¸ªè¯ï¼ˆæˆ–è€…å€¼æ˜¯ç©ºçš„ï¼‰ï¼Œè·³è¿‡
                continue

            items.append({"term": t, "translation": chosen})
            # ---------------------------


            term_annotations[str(cid)] = items

    print(f"Assembled term_annotations: {term_annotations}")
    return typing.cast(TermState, {"term_annotations": term_annotations})



@timed_node()
def build_graph() -> Runnable:
    graph: StateGraph[TermState] = StateGraph(TermState)

    graph.add_node("init", _init_extract_state)
    graph.add_node("terms_only_batch", _terms_only_batch)
    graph.add_node("select_top_terms", select_top_terms)
    graph.add_node("reflect_terms", reflect_sync_node)
    graph.add_node("aggregate_unique_terms", _aggregate_unique_terms)

    graph.add_node("batch_translate", _single_translate_concurrent)

    graph.add_node("assemble_annotations", _assemble_annotations)


    graph.set_entry_point("init")

    graph.add_edge("init", "terms_only_batch")

    graph.add_edge("terms_only_batch", "select_top_terms")

    graph.add_edge("select_top_terms", "reflect_terms")

    graph.add_conditional_edges(
        "reflect_terms",
        route_after_reflect,
        {
            "retry": "select_top_terms",       # ä»ç„¶åªå›åˆ° select_top_terms
            "proceed": "aggregate_unique_terms",
        },
    )

    graph.add_edge("aggregate_unique_terms", "batch_translate")

    graph.add_edge("batch_translate", "assemble_annotations")

    graph.add_edge("assemble_annotations", END)

    return graph.compile()
